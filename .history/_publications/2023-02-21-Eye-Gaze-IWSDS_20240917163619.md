---
title: "Towards integrating eye gaze tracking into a multimodal dialog agent for remote patient assessment"
collection: publications
category: conferences
permalink: /publication/2023-02-21-Eye-Gaze-IWSDS
excerpt: 'We demonstrate a prototype that integrates predictive eye gaze tracking into a multimodal platform for remote patient assessment and show validation through internal testing.'
date: 2023-02-21
venue: 'IWSDS'
paperurl: 'http://danieltisdale.github.io/files/Eye_Gaze_Tracking_Paper_IWSDS_2023.pdf'
posterurl: 'http://danieltisdale.github.io/files/Eye_Gaze_Tracking_Poster_IWSDS_2023.pdf'
citation: 'Tisdale, D., Liscombe, J., Pautler, D., & Ramanarayanan, V. (2023). Towards integrating eye gaze tracking into a multimodal dialog agent for remote patient assessment. In <i>Proceedings of the 13th International Workshop on Spoken Dialogue Systems Technology</i>.'
---

<b>Abstract:</b><br>
We demonstrate a prototype that integrates automated eye gaze tracking into an already existing multimodal conversational platform for remote patient assessment and monitoring (<b>NEMSI</b>; short for <b>NE</b>urological and <b>M</b>ental health <b>S</b>creening <b>I</b>nstrument). The platform engages patients in an interactive dialog session and guides patients through several spoken, orofacial, cognitive, and gaze tasks inspired by clinical protocols. Novel additions to the dialog protocol include a selection of exercises that have been widely used in oculomotor pathology research as well as clinical practice, including: smooth pursuit, saccade, free image exploration, directed image exploration, and the congruent and incongruent Stroop tests. Furthermore, the prototype automatically computes eye-gaze metrics in addition to speech, facial, linguistic, and motoric metrics relevant to the assessment of their overall neurological and mental health. Finally, we report on internal testing to validate the accuracy of real-time eye gaze software and metrics shown to be of use in clinical research.
